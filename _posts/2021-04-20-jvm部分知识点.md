### boolean的大小

boolean虽然只表示true和false，这意味着只要一个bit就可以表示，但是实际上无论是单个boolean或者是数组中的boolean，都会占用一个字节。这主要是为了防止
Word
Tearing（word撕裂），因为在jvm规范中，每一个filed或者数组中的每一个元素都被认为是独立的，更新单个值时不应该读取或者更新其他值，举例来说，两个线程同时访问数组的相邻变量，无需synchronized同步或者其他额外的操作。而jvm中的地址是按照byte来计算的（大部分现代操作系统中，内存操作都是按byte，读取1bit时可以将整个取出，然后通过位运算拿到对应的值，但是对于写操作，无论如何都需要将整个byte写入，因此两个并发操作就需要加锁比如cas来完成1bit的写入），所以对于1bit无法保证这个特性，最终只能选择用1byte来存储boolean。

### TLAB

java TLAB（thread local allocation buffers）

当我们new一个对象时，jvm需要为我们分配内存，通常分配内存的接口只需要两个

ref Allocate(T type)

ref AllocateArray(T type, int size)

但是实际上和内存打交道的语言并不是Java，hotspot虚拟机使用c++写的，意味着申请内存需要调用native代码，和native代码交互不仅花费比较高，并且内存分配需要处理多个线程的并发请求。为了减少native调用次数，调用native
code时会返回一个较大的块（大于new对象的大小），由jvm管理，后续申请内存时如果空闲的内存足够，就无需调用native
code。为了避免线程同时申请内存而不得不加锁导致的性能下降，预先为每个线程预留一个独占的内存缓存块，这就是TLAB（也被称为
pointer bump allocation 指针凸块分配）。但是TLAB大小是有限的，如果对象的大小远大于TLAB，则只能回退到之前的加锁同步分配内存的方法。（这里要提到CMS
GC，它并发清楚老年代是无需stw的，但是清除新生代时却要stw，因为新生代往往存活的对象很少，值得stw来清理出连续的内存供TLAB使用）。

TLAB缓解了并发内存分配的瓶颈，但是因为申请内存代价太小，可能导致更频繁的GC。相反的，如果没有这种内存分配优化，那么内存回收时需要通过native
code返回给系统。所以比较GC时要权衡这两方面。

由于TLAB是整个被独占地分配给单个线程的，所以GC没办法观测到TLAB内的实际占用，所以如果一个比较大的TLAB被分配给一个线程，但是线程只使用了其中一小部分(
实践中通常会自适应的分配TLAB的大小，我们可以启用Java的Epsilon GC来使TLAB大小固定)
，剩余的部分也无法被GC感知到(无法被感知到是因为TLAB剩余的内存被一个int[]
占用，从GC的角度来开，该内存已被使用，这点可以从内存溢出后的dump文件分析出来)
，当这种线程很多时，举个例子，尽管实际的对象大小只有900M，对GC来说，已经认为1G内存被占用满了并且无法回收，从而抛出outOfMemory。

### jvm对象初始化

理论上来讲，new一个对象时jvm至少要经过如下三个过程：分配内存、调用系统初始化、用户初始化。系统初始化是根据语言要求来进行的，c语言系统初始化什么都不做，而java每一个对象都需要系统初始化，包括生成对象头，给字段赋默认值。之后调用用户定义的初始化方法。实际上，HotSpot会对初始化进行优化，如果假设一个对象定义如下：

static class Init {
private int x;
public Init(int x) {
this.x = x;
}
}

假设现在new一个Init对象，new Init(42)
，逻辑上讲，hotspot会在系统初始化时先将x初始化成0，调用用户初始化时再赋值42，但是HotSpot会优化为系统直接初始化为42。但是如果我们在this.x=x这行代码之前添加一个函数调用，HotSpot就无法判断是否该函数会使用到x，这种情况HotSpot会按照最坏的情况，假设该函数会用到x，在系统初始时将其初始化为0.

这种小优化模糊了理论上的各个阶段的界限。

### java new对象或者数组时，主要性能消耗在初始化元数据（对象头这些）和字段（数组初始化所有值）

### java局部变量可能在代码块结束之前就被回收

c/c++中的局部变量会存活到所属的代码块结束，但是java有些不同，java规范中允许jvm提前将已经不用的对象设置为null以加快其GC回收，如果没有注意这个区别，试图在finalize方法中按照c/c++的逻辑处理，就可能比预先更早的执行从而引起问题。

### jni对gc的影响

java调用jni并传递数组对象时，

void * GetPrimitiveArrayCritical(JNIEnv *env, jarray array, jboolean *isCopy);

void ReleasePrimitiveArrayCritical(JNIEnv *env, jarray array, void *carray, jint mode);

上面这两个方法供native获取和释放数组对象，如果可能的话，jvm会将该数组的指针传递给native，此时就会给GC带来一些问题：因为实际上该部分内存还在使用，GC不应该回收这一部分。通常有如下策略：

1）完全停止GC，这是最简单的，但是如果jni停顿太长时间，Java其他线程分配的内存无法及时回收（paralle和G1都是这个策略）

2）固定这个对象，但是如果GC使用分代回收的策略，如果该对象存在于年轻代，那么固定期间GC不可以移动该对象，而通常来说年轻代会使用整理或者复制算法来回收，固定该对象提高了GC的复杂度

3）固定该对象所在的空间，综合以上两点，对于分代GC，固定包含该对象的内存块，不对该块进行回收（java15引入的shenandoah使用这个策略）

jni指南中规定，调用上面两个方法之间不应该执行长时间的操作（因为大部分GC实现使用了策略1），应该将两个方法之间的代码视为“关键区域”，该区域中，native
code禁止调用其他jni方法或者其他可能造成当前线程阻塞到其他java线程的系统调用，因为在完全停止GC的实现中，这会导致死锁，当然java15的shenandoah
GC不存在这个问题，但是代码可用性不应该取决于GC的实现，所以要避免这类操作。

### 没有必要使用String.intern

String的intern方法允许我们将string手动法如字符串常量池中，看起来是一个很诱人的性能优化方案，但是在实践中，起码有以下三个缺点阻止我们使用该方法：

1）字符串常量池由jvm维护，底层是一个c++的hashtable，所以intern是一个native方法，而调用native方法不可避免地带来性能损耗。

2）c++实现的hashtable，像我们平常使用的java中的hashmap一样，并发、数据量都会影响其性能，java中concurrent包下面提供了优化并发操作的map，并且java中的hashmap会自动扩容，但是c++实现的hashtable并没有与时俱进的实现并发功能，更致命的是，该hashtable是无法扩容的，只能在启动时指定其大小，这意味着，如果给一个初始比较小的hashtable放入大量字符串，会导致hash冲突非常多，并且冲突是通过链表来解决的，链表的查找性能进一步影响了该hashtable的性能

3）字符串常量池是GCroot之一，而GCroot的大小会很大的影响GC的标记性能，GCroot中元素数量和GC扫描时长成正比，通常情况下，字符串常量池中的大部分字符串来自加载的类，而加载的类通常不容易被卸载，所以通常的GC实现中，极少会主动检测和压缩字符串常量池的大小，所以手动intern只会使GC情况更加糟糕。

综上，String.intern几乎在任何情况下都是一个糟糕的选择，甚至不如手动在java中维护一个类似的表，起码可以自己来维护并发、扩容相关的操作，甚至性能可能反而更好。

### class data sharing（CDS）

CDS可以减少jvm的启动时间，特别是在小的应用中。如果是通过安装包安装的jre，安装过程中会自动将system的jar
包中的一些类转为内部表示并dump到一个文件中，称为“共享档案（shared
achieve）”。如果不是通过安装包安装，也可以手动触发。这个共享文档包含了内存映射，可以缩短多个jvm生成这些class元数据的时间。这个功能只在HotSpot客户端模式下，并且GC为serialGC时才可用。

### jvm内存占用

如果你只有512M内存，那么你尝试设置-Xmx
512m，java堆大小最小为512时会抛出内存不足。这是因为java在运行时需要额外的内存，这些内存并不算在java堆内存中。使用javaNMT（native
memory tracking）工具可以看到内存的真实占用情况，包含以下部分：

Java heap Java堆，没啥好说的

Class jvm加载的class，通过上面提到过的CDS功能，可以减小这部分内存占用

Thread 线程栈需要内存，通常每个栈大小为1M，可以通过jvm参数-Xss调整最小大小，注意调小后会增加stackoverflow的风险

Code 代码缓存，可通过 -XX:InitialCodeCacheSize=4096 来调节初始值，但随着编译进行，这个大小会膨胀

GC
后台GC线程也会占用内存，并且GC占用的内存会随着分配的堆内存大小改变，通常大小接近Java堆的3%-4%，不同的GC实现占用内存也不同，通常来说serial因为只需要一个线程，所以是最轻量级的，占用内存最小

Compiler JIT的编译器，JIT自身也需要线程，可以通过jvm参数减少JIT线程的数量

Internal Symbol

Arena Chunk
jvm默认的参数是为了长时间运行的程序考虑的，对于短时间的程序，一些预分配的内存可能显得没那么有必要，此时我们可以通过NMT工具，查看内存占用，调整jvm参数来更好的利用内存。

可以通过-XX:MaxRam=500m来限制jvm真正内存占用，此时的java堆内存大概250m

### java常量

常量是类中static final的字段，对于基本类型和String类型，如果声明时就将该常量初始化（或者static块中初始化），则该常量编
译时会内联到字节码中。如果时构造函数中初始化（或者非static块，之前提到过，非static块代码会被编译器复制到每一个构造函数中），
字节码中还是变量（这里依然指基本类型和String类型），这就意味着，可以在运行时通过反射修改。而内联到字节码中的常量，我们无法修改。
内联的常量，因为少了一步取值，性能会略微高一些。

### JIT常量

与上面10有所区别，JIT常量是指那些非基本类型也非String的常量，因为其值需要在运行时计算出，所以无法内联到字节码（并且懒加载
的策略也不允许我们提前计算出值），但是JIT编译器在加载该类时会进行优化，当再次访问该类时，JIT会知道已经计算出了该值。

### 信任非static但是final字段

之所以只声明为final字段不会内联，是因为即使声明为final，还是可以通过反射、反序列化等方式修改它的值，编译器只能考虑最坏的
情况（存在例外的情况，比如匿名类中的final，或者包装类、String)。但是jvm给我们提供了一个参数，-XX:
+TrustFinalNonStaticFields
如果确定将final字段内联也不会对程序产生影响，则可以使用这一实验性的特性。

### 多态

编译型语言多态通常通过虚拟方法表（virtual method table）实现，大部分编译器都会隐式的给class加个成员，这个成员指向虚拟方法表。
这个表是一个方法的数组，用于在运行时匹配合适的方法实现，因为在编译期无法知道通过父类调用的方法实际上应该调用哪个实现。
因为在运行时由额外开销，所以对应的重写越多，性能会越差。但是不必过度担心，jvm运行时帮我们优化了很多。

### 操作数溢出

在x86架构上，由16个通用寄存器（并不是都可用），而比较新的处理器中，为了处理FPU和矢量运算，还提供了额外的寄存器（AVX寄存器）。
在虚拟操作数中，我们提供的寄存器数量往往大于实际数量，超过的部分在运行时只能存储在栈上，这称为操作数溢出，而栈的速度要比寄存器慢得多。
而AVX寄存器不执行对应指令时时空闲的，我们能不能用它们来暂存溢出的操作数呢，答案时可以的。HotSpot可以通过参数
-XX:+UseFPUForSpilling
来指定是否开启该功能，该功能在支持的架构上时默认开启的。

### jvm运行时null检查

jvm运行时需要检查对象是否为null，如果是null则访问时将抛出空指针异常，按照这个逻辑，我们可能需要在每次访问对象时都坚持该对象是否为null，
当然JIT可以隐式推断一些字段必定不是null，比如说静态初始化的字段，也可以根据数据流，在第一次判断非null后后续访问不再判断。
但是考虑到一个正常设计的java程序，发生空指针的几率并不高，这就让我们有动力通过增加真正发生null时的开销来减少正常情况下的开销，
即：并不显式检查null，而是用户代码真正访问到null对象时产生一个错误信号，另外记录一个关于这个信号的map，根据这个错误信号发生的位置，
到map中查询真正发生异常的代码位置，之后就可以根据这个信息抛出空指针异常。LLVM也用同样的方式处理null。但是，JIT如果发现某段代码经常性的抛出null，
则JIT可能会重新编译这段代码，加入显式的null检查。

### 自动生成的hashcode

hashcode要求同一个对象hashcode必须相同，不同的对象，即使是同一个类，也应该不同。首先想到的就是对象在内存中的地址，
但是用地址作为hashcode有两个缺点：1、不够分散 2、GC通常会移动对象，导致对象的内存地址发生变化，但是，移动后的对象hashcode不应该发生变化。
一个好的hashcode实现应该具有良好的分散性和幂等性。

为了生成hashcode，HotSpot有如下几种实现：

```java
        if(hashCode ==0){
        // Use os::random();  系统提供的伪随机数 java7和之前默认
        }else if(hashCode ==1){
        // Use address with some mangling 休整后的地址
        }else if(hashCode ==2){
        // Use constant 1 常量1，所有对象hashcode相同，仅用于测试
        }else if(hashCode ==3){
        // Use global counter 全局计数器
        }else if(hashCode ==4){
        // Use raw address 使用原生地址（低32位）
        }else{
        // Use thread-local PRNG 使用threadlocal的随机数生成  Java8和之后默认  
        }
```

可以通过XX：hashcode=？来调整。首次调用生成hashcode之后，会保存到对象头markword中（64位jvm中hashcode31位，32位系统中hashcode25位），
后续直接取用该值。性能os的伪随机数最差，因为它需要原子更新系统的伪随机数生成器，其他几种方式性能接近。

### java解释器和编译器

对HotSpot来说，java代码最初运行在字节码解释器上，随着称为热点代码，HotSpot使用C1基线编译器编译为本地代码，如果代码还是热点，
HotSpot会使用优化更加激进的C2编译器将其编译为本地代码。对于分支来说，jvm会尝试记录每个分支的频率，对使用频率更高的分支，
编译器有可能会重构编译后的代码布局，使频率更高的分支代码位于整个分支代码块的更靠前的位置。虽然现代CPU的分支预测一定程度上缓解
了普通情况下热点分支代码靠后带来的性能影响，但是直接重构代码布局显然来的更直接一些。

### JIT编译器作用范围

JIT编译器作用与方法。当一个方法成为热点代码，运行时系统会通知JIT，让其编译生成一个优化的版本。如果简单的认为，JIT将整个方法的代码编译
然后返回给运行时系统，就有点天真了，实际上，运行时系统还可以告诉JIT编译器它对该方法行为的某种假设。例如如下代码：

```java
void m(boolean flag) {
    if (flag) {
// do stuff A
    } else {
// do stuff B
    }
}
```

只从代码分析，JIT编译器会将两个分支都进行编译，因为JIT不知道flag的传入情况，但是实际上，运行时系统如果发现else分支从来没有运行过，
那么它可以告知JIT编译器，从而JIT无需编译else分支的代码，减少了编译所需时间，提高了代码密度。此时会在else分支放一个trap，
如果后续的代码真的执行到了else分支，说明之前的预计被打破了，JIT会重新编译生成else分支的代码。

### 数组内存对齐

数组在内存中分配时，包含一个mark word，一个class pointer以及数组长度，之后时数组数据。而数组数据开头也需要内存对齐，对齐
大小根据机器word大小，32位或者64位，即数组数据起始地址按照4字节或者8字节对齐。

### 为什么默认Object按照8字节对齐

1）、我们会经常访问对象的mark word，在64位下，mark word是8字节，为了一次性将其取出，所以通常按照8字节对齐，可能会问32位
下是否可以按4字节对齐，答案是不可以，具体原因可以阅读下面的几项

2)、方便violate修饰的long、double数据原子访问，它们占用8字节，所以最好按照8字节对齐。
对齐并不仅仅意味着浪费，对齐之后通过compressed reference，可以使用更多的内存，在32位系统中，不使用引用压缩，只能寻址4GB内存，
而通过8字节对齐，配合引用压缩，可以寻址32GB。

在HotSpot中，内存对齐是Object自带的属性，每个对象都会在最后选择是否保留一段内存，使其总占用为8的倍数。

### 内存对齐造成的影响

1）、有些情况下添加字段不会使对象占用内存增大，因为原来这些空间因为内存对齐浪费了，添加字段后刚好填充了这一部分

2}、有些情况下，即使添加一个占用空间很小的字段，比如1字节的boolean，会导致对象占用内存增加8个字节（具体取决于对齐的大小）

### 字段对齐

上面我们已经讨论了Object在内存中默认按照8字节对齐，而在许多体系结构中，系统不太喜欢没有对齐的内存访问：

    1）、未对齐的访问性能可能较差  

    2）、Java标准中，violate修饰的字段需要原子访问，而long和double类型数据，如果没有对齐，可能会被拆分为两个4字节分别存取，在并发访问中，可能造成问题。 

上面这些原因，让jvm实现更加倾向于字段也对齐。比如在一个long类型字段为了内存对齐，可能在其前方添加一个4字节的padding。当然，
jvm也有一些优化，如果long字段后面还定义了一个小于等于4字节的字段，比如int，那么会将这个后续字段填充到padding内，可以说是将该字段隐藏在了间隙中。

### 字段填充

如22所说，jvm会按照字段的大小对齐进行内存对齐，而这不可避免地会造成Object的内存布局中存在padding，为了充分利用这些padding，
Object的内存布局和Object中字段声明的顺序不一定相同，jvm可能会将后面声明的字段填充到前面的padding中，所以内存中的字段顺序和程序中声明的字段顺序并不一定相同。

这还带来了另外一个问题：类似c语言的手动内存padding在java中不再可靠。为了防止false sharing（简单的来说，系统中缓存是按照块来更新的，
如果相邻的字段占用都很小，就可能被分配到同一个缓存块中，这样的话一个字段缓存失效会导致整块缓存被更新，导致另外一个字段的缓存失效了，
再次访问另一个字段时也会有同样的情况），c语言中可以通过在小字段间声明几个无用的字段，将原本相邻的两个字段分隔开，进入不同的缓存块。
例如，原本有两个相邻的byte字段，很可能被分配到同一个缓存块中，通过在他们之间声明几个long字段，可以把他们分隔开来，进入不同的缓存块。
但是因为java中字段填充会优化，导致这种用法不一定生效。其实java中有一个@Contended注解，可以禁止jvm这项优化，但是这个注解只能被jdk本身使用。

### 如何绕过jvm的字段填充（即23）

有没有办法绕过jvm的字段填充优化呢，有如下办法：

1）、@Contended注解，但是只有jdk自身可以使用

2）、继承。在jdk15及以前，如果B继承了A，那么B中的字段不会 被填充到A的padding中。但是jdk15之后这个行为改变了，也会被jvm优化

### java静态方法、接口方法、抽象类方法的性能

这里的接口方法是指通过接口对象调用实现（即A implements B，通过类型B调用方法），抽象方法是指通过抽象父类调用子类实现（即A
extends AbstractB，通过AbstractB调用方法）。

通常来说，针对只有一个实现的接口和只有一个子类的抽象类，静态方法性能>>抽象类方法性能>接口方法性能。

他们分别对应字节码invokestatic、invokeinterface、invokevirtual。

对于有多个实现的接口和抽象类（此时静态方法已无法判断应该调用哪个，所以不再列入比较范围），抽象方法性能>
接口方法性能。运行时，抽象方法有一个virtual calls table（简称vtable），接口方法有一个interface calls
table（简称itable），因为java是单继承的，接口可以实现多个，所以itable要比vtable复杂，运行时确定应该调用哪个方法时，itable的访问要比vtable更加费事。

### JIT编译器什么时候开始工作（client模式下只使用c1编译器，server模式下jdk7以前使用c2，jdk7以后使用c1和c2梯度模式）
JIT编译器在调用java方法时激活，将方法的byte code编译为native code，以获取接近native的性能。JIT编译也需要占用cpu和内存资源，
特别是jvm刚启动时，大量的方法被调用，如果每个方法都通过JIT编译，会显著影响jvm启动时间。所以在实践中，方法第一次被调用时并不会立
马通过JIT编译，而是为每个方法保存一个计数，每次调用计数都增加，知道达到JIT预设的阈值，才会启动JIT编译。第一次编译之后，该计数清零，
之后每次调用依然会增加计数，当计数再次达到某个阈值（默认c1编译器1500次，c2编译器10000次），JIT会进行一次更加优化的编译。这个过
程不断重复，知道达到最大的优化级别。（参照17，18，第一次的JIT编译不会考虑太多优化，因为这一步最重要的是尽快将byte code转为native
code，如果之后方法还在频繁的调用，我们有理由相信值得花费更多时间在编译成更优化的native方法上面，所以会启动更高级别的编译，
而且如18所说，编译时还可以从runtime获取更多信息，为优化提供更多可能，也就是说，即使已经达到了最高级别的优化等级，但是从runtime
获取到了新的情报，比如说某一类型的数据比例最高，JIT也可能根据这个情报，重新优化编译）。

### JIT如何工作

jvm通常会启动多个JIT编译线程，取决于系统配置，通常情况下多线程可以加快jvm启动时间。可以通过jvm参数控制线程数量，要注意，
如果JIT线程数量超过了可用CPU核数，继续增加也无法提高编译性能。

开始JIT编译时，首先会将bytecode转为一个语法树，通过优化分析这棵树，最后生成机器码。

JIT编译主要有以下几个流程：

1）、内联

内联会将比较小的方法内联（合并）到调用方

<1>小方法直接内联

<2>通过带权重的调用流程图进行优化（通常由自顶向下、自底向上、最高权重优先三种方式）

<3>消除尾递归

<4>优化虚方法调用（比如只有一个子类的虚方法调用直接优化掉）

2）、局部优化

使用不同的优化方法优化小段代码

3）、控制流优化

通过分析控制流，重排代码分支路径以提高效率

4）、全局优化

优化整个方法，代价比较高，但是可以取得很好的效果

5）、生成native code 

 