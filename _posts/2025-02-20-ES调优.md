
## terminate_after参数
terminate_after参数用于提示ES在每个shard收集到指定数量的文档后就提前停止，特别适用于检查是否存在符合条件的文档，将terminate_after设置为1，那么每个shard获取到第一个符合条件的文档后就会中止，优化性能。

terminate_after作用优先于track_total_hits和sort，指定terminate_after后track_total_hits只会返回每个shard扫描到的terminate_after的总数。指定terminate_after后，查询返回值会包含terminate_early字段,字段值为true。

下面的例子中，指定了terminate_after为1000，shard数为5，那么track_total_hits返回5000，不指定terminate_after则正常返回
```shell
curl localhost:9200/conn_index_2025.03.24/_doc/_search?pretty -d '{"terminate_after":1000,"track_total_hits":true,"size":0}' -H 'content-type: application/json'
{
  "took" : 1,
  "timed_out" : false,
  "terminated_early" : true,
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 5000,
      "relation" : "eq"
    },
    "max_score" : null,
    "hits" : [ ]
  }
}

curl localhost:9200/conn_index_2025.03.24/_doc/_search?pretty -d '{"track_total_hits":true,"size":0}' -H 'content-type: application/json'
{
  "took" : 1,
  "timed_out" : false,
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 10958192,
      "relation" : "eq"
    },
    "max_score" : null,
    "hits" : [ ]
  }
}
```
sort查询同样受影响，所以需要排序的查询不能使用这个优化


## timeout
查询时指定timeout参数，可以避免耗时太长的任务消耗资源，timeout参数提示每个shard在规定的时间内返回数据，如果未能处理完成，默认情况es会处理当前已经积累到的数据。如果想要超时后直接报错而不是处理部分数据，可以指定allow_partial_search_results参数为false，这样超时后会返回一个错误而不是部分的处理结果。

注意区分客户端和服务端的超时，上面说的timeout是服务端的超时，服务器会尽量在这个时间内返回结果，而客户端设置超时返回后服务端并不会停止，不过es在连接关闭时会自动取消当前连接的查询，所以客户端超时后如果没有设置服务端超时，可以断开查询的连接，让服务端自动取消.


## routing
routing用于确认文档会被路由到哪个shard，默认情况下，es使用_id字段作为路由，算法也很简单，字段hash对主分片数求余。用户在添加文档时，可以指定routing，例如
```
PUT /my_index/_doc/doc_id?routing=aaa
{
    "user_name":"aaa",
    "age":10
}
```
后续查询时同样携带routing参数，会自动选择所在的分片。
es的mapping可以指定routing字段必填，这样的话没有routing字段的文档无法添加

需要注意的是如果索引中既有默认的routing(没有显示指定，默认_id字段),又有手动指定routing（添加时手动指定了routing），那么后续查询时如果携带了routing，会按照routing规则过滤掉其他shard，这种情况下如果是按照某个字段进行的routing，但是有部分文档没有按照这个routing添加，这部分文档就可能落到其他shard上，使用routing查询时确定的shard不包含其他shard，导致数据查询不完整。所以这种情况，查询不能指定routing

特别注意，因为routing的算法是取模，如果字段区分度很低，会导致大部分数据路由到同一个shard上，导致数据分布不平衡，也无法充分利用多shard的性能和容错的提升，所以要谨慎选择routing字段。


## alias
alias可以指向一个或多个索引，可以理解为软链接，可以通过alias提供无缝迁移，或者组合多个索引。
alias支持filter，这样alias代表某个索引数据的子集
alias支持指定routing值，这样通过alias写入的数据自动使用这个routing，通过alias查询的数据也自动携带这个routing

注意，alias指向多个索引时无法写入，此时会报错


## sql api
```
localhost:9200/_sql?format=txt
{
    "query":"select count(*) from \"conn_index_2025.01.01\""
    "filter": {
       "range": {
           "timestamp": {
                 "gt": 0
           }
       }
    }
}
```
format可选txt，json，csv等，默认是json。表名就是索引名，索引名包含.时需要用双引号将整个索引名括起来。

同时支持标准查询的filter查询.

支持分页查询，limit/offset直接对应from/size，也可以通过fetch_size配合cursor实现类似数据库游标的操作，底层是基于scroll，所以cursor是有状态的，不用时需要关闭。.
总的来说，search_after是在from/size不适用的情况下一个轻量级的选择，它无状态，占用资源低。cursor和scroll则占用较高。目前sql api暂时没有对应search_after的功能。


es bin目录下的sql-cli更适合在命令行中执行sql

/_sql/translate节点会返回底层的查询，debug时很有用，参数与/_sql完全一样


## shard和segment
一个shard是一个Lucene实例，其中包含多个segment，对于不再写入的索引，可以将segment合并以提高检索效率
查看shard和segment
```
GET /_cat/shards?v&pretty
GET /_cat/segments?v&pretty
```

强制合并segment并指定合并后数量为1
```
POST localhost:9200/my_index/_forcemerge?max_num_segments=1
```

## shrink和reindex
这两个都可以用于复制索引，但是shrink要求源索引必须是read only的，reindex则更通用一些。reindex会生成一个snapshot用于后续数据迁移，shrink则不需要，所以对于不再写入的索引，shrink更加合适。

reindex期间数据还是可以写入原有索引，es不负责这部分的数据迁移，所以有需要的话需要自行保证数据一致

一个完整的reindex流程

```shell
获取原索引mapping
curl localhost:9200/index_from/_mapping > mapping

修改mapping内容
原始mapping大概这样
{
  "index_from" : {
    "settings" : {
        //一些索引设置，比如shard，replica，indexsort
        },
    "mappings" : {
        //字段类型映射
        }
   } 
}

去掉最外层的index_from,只保留settings和mappings,按需编辑某些字段
{
    "settings" : {
        //一些索引设置，比如shard，replica，indexsort
        },
    "mappings" : {
        //字段类型映射
        }
}

为新索引创建mappint
curl -XPUT localhost:9200/index_to -H 'content-type: application/json' -d @mapping

开始reindex
curl -XPOST localhost:9200/_reindex -H 'content-type: application/json' -d '{"source":{"index":"index_from"},"dest":{"index":"index_to"}}'
```

## pit(Point In Time)和scroll
pit类似于scroll，相当于创建了一个快照，后续配合search_after可以完成和scroll类似的功能。不过有以下区别需要注意：
> pid创建时不附加查询条件，所以pit不需要保存额外的查询上下文，比scroll更轻量
> pit创建后可以执行任意查询，这点与scroll创建后只能遍历结果集不同
> pit和scroll创建后，后续写入的数据均不可见

除非要查询大量数据，大部分情况下都推荐用pit配合search_after


## 文档大小限制
默认es限制最大100M，底层Lucene限制最大2G，2G这个限制是硬上限。

## 加速索引
1、bulk，多线程
2、增加refresh interval,如果确定数据可以放到同一个segment，直接将refresh_interval设为-1，这样会禁止生成多余的segment,导入结束后重设
3、初始添加数据是设置replica数量为0，稳定后修改为其它值
4、增加indices.memory.index_buffer_size
5、单个shard是顺序写入的，对于单个shard来说多线程写入提升不大，多个shard采用多线程可能有明显的性能提升

## 加速查询
1、提供更大的内存供操作系统file cache
2、检查磁盘readahead设置，现代操作系统随机io时通常会直接读出整块的数据，hdd硬盘这个值通常是4kb，但是如果使用阵列或者lvm，这个值可能到达1m，导致读取很小一部分数据时实际上读出了一堆无用数据并且占用file cache，导致热点数据被evict，通过lsblk -o NAME,RA,MOUNTPOINT,TYPE,SIZE命令的RA列查看磁盘的readahead设置。
3、减少返回的字段数量
4、对于不用range查询的数字字段，可以设置为keyword加速term查询，如果同时需要range和term，那么设置两个类型字段


## near real time
es基于Lucene，而Lucene每次执行写入操作后，数据并不能立马被查询到，es的_refresh是基于Lucene的near real time语义完成的。在没有提供near real time功能之前，数据只有被持久化到磁盘上的segment之后才能被检索到，也就是需要等执行完IndexWriter的commit或者close方法，但是commit方法是个比较重的操作，需要fsync确保文档被写入磁盘，在near real time中，数据可以临时存储在内存中的buffer中，这里也要求生成segment后才能被检索到，不过这里生成的segment没有调用commit被持久化到磁盘，而是暂存在内存中，这个segment一旦生成同样是不可变的，与普通segment的区别仅在于尚未被持久化，这样无需调用commit也可以被检索到。这个生成内存中segment的api称为refresh，但是refresh并没有在IndexWriter中提供，而是由SearcherManager接管IndexWriter后进行管理

## doc_value 和 index.sort
doc_value以文档id(_id字段)->value的格式按照文档id的顺序保存，所以doc_value只是加快了对应字段从_id到value的查询，对doc_value的排序操作仍然需要读取所有的doc_value进行全局排序。
指定index.sort的字段必须启用doc_value(不需要开启，es会自动启用，但是不能显示禁用doc_value,否则会报错)，因为后续操作需要频繁查询该字段的值，使用doc_value加速查询。底层实现是Lucene的indexSorter，用于生成segment时按照某字段排序后写入。
index.sort字段选用更小的类似，比如long改为int，能显著提高性能

## read_only
es使用中许多索引是按天生成的，旧的索引基本上不再写入，此时可以将其设置为readonly，这样可以避免维护merge、refresh等的开销，也有利于es对查询缓存的优化。操作如下

```
curl -XPUT localhost:9200/my_index/_settings -H 'content-type: application/json' -d '{"index.blocks.read_only": true}'
```
